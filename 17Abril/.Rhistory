# EJEMPLO 2
# Obtener valores de una Normal bivariante Usando la funci√É¬≥n mvrnorm del paquete MASS
bivn=mvrnorm(10000, mu=c(5,5), Sigma=matrix(c(1,0.7,0.7,1),2))
hist(bivn[,1])
install.packages("MASS")
library("MASS", lib.loc="~/R/win-library/3.4")
# EJEMPLO 2
# Obtener valores de una Normal bivariante Usando la funci√É¬≥n mvrnorm del paquete MASS
bivn=mvrnorm(10000, mu=c(5,5), Sigma=matrix(c(1,0.7,0.7,1),2))
hist(bivn[,1])
# dibujos
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
image(bivn.kde)
contour(bivn.kde, add = T)
hist(bivn[,1])
# dibujos
bivn.kde <- kde2d(bivn[,1], bivn[,2], n = 50)
image(bivn.kde)
contour(bivn.kde, add = T)
# # EJEMPLO 3
# de una Normal bivariante a partir de la marginal para x1, y la condicionada x2|x1
# usando que la condicionada tambi√É¬©n es normal
z1=rnorm(1000)
z2=rnorm(1000)
x1=5+z1
x2=5+0.7*z1+sqrt(1-0.7^2)*z2
hist(x2)
head(bivn)
# EJEMPLO 1
# Multinomial, por ejemplo n=20, prob=c(0.3,0.2,0.5)
# Primero una Bin(20, 0.3)
m=40
muestra=matrix(nrow=3, ncol=m)
p=c(0.3,0.2,0.5)
for(i in 1:m){
x1=rbinom(1,20,p[1])
x2=rbinom(1,20-x1,p[2]/(1-p[1]))
x3=20-x1-x2
muestra[,i]=c(x1,x2,x3)
}
View(bivn)
View(bivn.kde)
muestra
#### # EJEMPLO 4
# Muestreador de Gibbs con variable aleatoria bidimensional discreta. Inicializaci√É¬≥n
BcondA=matrix(c(0.6,0.667,0.5,0.4,0.333,0.5), nrow=2, ncol=3, byrow=TRUE)
AcondB=matrix(c(0.5,0.5,0.334,0.25,0.166,0.25), nrow=3, ncol=2, byrow=TRUE)
a=1
b=1
margA=NULL
margB=NULL
samples=matrix(0, nrow=2, ncol=3)
#for loop
for(i in 1:1000){
b=sample(c(1,2),1,prob=BcondA[,a])
a=sample(c(1,2,3),1,prob=AcondB[,b])
margA=append(margA,a)
margB=append(margB,b)
samples[b,a]=samples[b,a]+1
}
samples
samples/1000
table(margA)
table(margA)/1000
table(margB)/1000
samples/1000
### # EJEMPLO 5
## Gibbs de la Normal Bivariante de media (0.0), \sigma^2_x=\sigma^2_y=1
#  y coeficiente de correlaci√É¬≥n \rho
gibbsBVN=function(x,y, n, rho){
#create a matrix to store values
m<-matrix(ncol=2,nrow=n)
#store initial values in matrix
m[1,]<-c(x,y)
#sampling iteration loop
for (i in 2:n){
#rnorm takes sd not variance
#update x conditional on y
x<-rnorm(1,rho*y,sqrt(1-rho^2))
#update y conditional on x from above
y<-rnorm(1,rho*x,sqrt(1-rho^2))
#store values in matrix
m[i,]<-c(x,y)
}
m
}
# gr√É¬°ficos para ver los distintos puntos iniciales
NormalG1=gibbsBVN(0,0,1000,0.8)
plot(NormalG1)
lines(NormalG1)
NormalG2=gibbsBVN(-2,3,1000,0.8)
plot(NormalG2, type='p')
lines(NormalG2)
dim(NormalG1)
plot(NormalG1)
lines(NormalG1)
NormalG2=gibbsBVN(-2,3,1000,0.8)
plot(NormalG2, type='p')
lines(NormalG2)
NormalG2=gibbsBVN(-4,4,1000,0.8)
lines(NormalG2)
plot(NormalG2, type='p')
lines(NormalG2)
# gr√É¬°ficos para ver los distintos puntos iniciales
NormalG1=gibbsBVN(0,0,1000,0.8)#Normal de media 0,0 de tama√±o 100 y empieza en el pto 0.8
plot(NormalG1)
lines(NormalG1)
NormalG2=gibbsBVN(-2,3,1000,0.8)
plot(NormalG2, type='p')
lines(NormalG2)
## EJEMPLO 6
## Ejemplo del libro, de Gibbs
#valores iniciales
x1=vector()
x2=vector()
x2[1]=0.4
x1[1]=0.34
## for loop
for (i in 2:2000){
x1[i]=rexp(1,rate=1+x2[i-1]^2)
x2[i]=rnorm(1, mean=0, sd=sqrt(1/(2*x1[i])))
}
hist(x1[1000:2000], freq=FALSE)
# superpongo la funci√É¬≥n de densidad marginal de x1 (la he obtenido resolviendo la integral)
curve(exp(-x)*(sqrt(1/(2*x)))*sqrt(2*pi)*(1/pi), from=0, to=8, add=TRUE, col=2)
#para la segunda componente, que resulta tener distribuci√É¬≥n de Cauchy (hecha la integral a mano)
hist(x2[1000:2000], xlim=c(-600,600),freq=FALSE)
curve((1/(1+x^2))*(1/pi), from=-600, to=600, add=TRUE, col=2)
ks.test(x2, "pcauchy")
ks.test(x2[1000:2000], "pcauchy")
## conjunta
plot(x1,x2, pch=20)
# EJEMPLO 6 hecho directamente, por la regla del producto:
# f(x1,x2)=f(x2)f(x1|x2)
# calculando la marginal para x2, que es Cauchy:
r1=rcauchy(1000)
rate1=(1+r1^2)
r2=rexp(1:1000,rate=rate1)
plot(r2,r1, pch=20)
hist(r2)
pch
## conjunta
plot(x1,x2, pch=20)
# EJEMPLO 6 hecho directamente, por la regla del producto:
# f(x1,x2)=f(x2)f(x1|x2)
# calculando la marginal para x2, que es Cauchy:
r1=rcauchy(1000)
rate1=(1+r1^2)
r2=rexp(1:1000,rate=rate1)
plot(r2,r1, pch=20)
hist(r2)
plot(r2,r1, pch=20)
# This function is a Gibbs sampler
##
# Args
# start.a: initial value for a
# start.b: initial value for b
# n.sims: number of iterations to run
# data: observed data, should be in a
# data frame with one column
data=read.table("data-exponential.csv")
data
##
# Returns:
# A two column matrix with samples
# for a in first column and
# samples for b in second column
sampleGibbs <- function(start.a, start.b, n.sims, data){
# get sum, which is sufficient statistic
x <- sum(data)
# get n
n <- nrow(data)
# create empty matrix, allocate memory for efficiency
res <- matrix(NA, nrow = n.sims, ncol = 2)
res[1,] <- c(start.a,start.b)
for (i in 2:n.sims){
# sample the values
res[i,1] <- rgamma(1, shape = n+1,
rate = res[i-1,2]*x+1)
res[i,2] <- rgamma(1, shape = n+1,
rate = res[i,1]*x+1)
}
return(res)
}
sum(data)
nrow(data)
# Simulaci√É¬≥n de un sistema M/M/1. Tasa de llegadas lambda=2 y tasa de servicios mu=3.
lambda = 2
mu = 3
# tiempo que dura la simulaci√É¬≥n
time = 10000
t = 0
# Q_hist[n] es el n√É¬∫mero de personas en el sistema antes de que se produzca el suceso n-√É¬©simo
Q_hist = 0
# s es la suma acumulada para calcular la longitud media de la cola
s = 0
# El sistema est√É¬° inicialmente vac√É≠o. Generamos la primera llegada:
T1 = rexp(1,rate=lambda)
Q = 1 # n√É¬∫mero de clientes en el sistema
event_times = T1
t = T1
num_event = 1 #n√É¬∫mero del suceso, √É¬©ste es el primero
while (t<time) {
num_event = num_event+1
if(Q>0) {
# comprobamos que el sistema no estaba vac√É≠o
T1 = rexp(1,rate=lambda+mu)
p = runif(1,0,1)
Q_hist[num_event] = Q
Q = ifelse(p<lambda/(lambda+mu),Q+1,Q-1)
} else {
# Si el sistema estaba vac√É≠o, solo son posibles llegadas
T1 = rexp(1,rate=lambda)
Q_hist[num_event] = Q
Q = 1
}
t = t+T1 # actualizamos el tiempo de la simulaci√É¬≥n
event_times[num_event] = T1 # actualizamos el tiempo entre sucesos
s = s+T1*Q_hist[num_event] # he pasado un tiempo T1 con una cola de Q_hist[num_event] clientes
}
# s/t es la longitud media de la cola.
plot(cumsum(event_times),Q_hist,type="s", xlab="Tiempo",ylab="Longitud de la cola",
main="M/M/1 Simulation")
mtext(paste("longitud media de la cola=",s/t))
# Tambi√É¬©n la podemos estimar como:
sum(Q_hist*event_times)/10000
# Proporci√É¬≥n de tiempo en la simulaci√É¬≥n en la que la cola tiene longitud 0:
sum(event_times[Q_hist==0])/t
# El valor te√É¬≥rico es pi_0=1-rho, con rho=lambda/mu
1-lambda/mu
# Proporci√É¬≥n de tiempo en la simulaci√É¬≥n en la que la cola tiene longitud 1:
sum(event_times[Q_hist==1])/t
# El valor te√É¬≥rico es pi_1=(1-rho)*rho, con rho=lambda/mu
(1-lambda/mu)*(lambda/mu)
# Paquete simmer: Discrete-Event simulation for R. Sistema M/M/1. Este paquete utiliza ggplot2 para
# los gr√É¬°ficos.
lambda <- 2
Q_hist[1:10]
event_times[1:10]
t
scumsum(event_times[1:10])
cumsum(event_times[1:10])
# Tambi√É¬©n la podemos estimar como:
sum(Q_hist*event_times)/10000
# s/t es la longitud media de la cola.
plot(cumsum(event_times),Q_hist,type="s", xlab="Tiempo",ylab="Longitud de la cola",
main="M/M/1 Simulation")
mtext(paste("longitud media de la cola=",s/t))
# Tambi√É¬©n la podemos estimar como:
sum(Q_hist*event_times)/10000
max(Q_hist)
# Proporci√É¬≥n de tiempo en la simulaci√É¬≥n en la que la cola tiene longitud 0:
sum(event_times[Q_hist==0])/t
# El valor te√É¬≥rico es pi_0=1-rho, con rho=lambda/mu
1-lambda/mu
# Proporci√É¬≥n de tiempo en la simulaci√É¬≥n en la que la cola tiene longitud 1:
sum(event_times[Q_hist==1])/t
# El valor te√É¬≥rico es pi_1=(1-rho)*rho, con rho=lambda/mu
(1-lambda/mu)*(lambda/mu)
install.packages("simmer")
library("simmer", lib.loc="~/R/win-library/3.4")
